# from airflow import DAG
# from airflow.models.param import Param
# from airflow.decorators import task
# from datetime import timedelta
# import pendulum
#
# # Import tasks t·ª´ module c·ªßa b·∫°n
# from ELT.extract.extract import ingest_to_minio_bronze
# from ELT.load.load import merge_to_silver_duckdb_native
#
# # --- C·∫§U H√åNH LOGIC CH·ªåN NG√ÄY ---
# # V·∫´n gi·ªØ logic Manual Override c·ªßa b·∫°n
# GET_YEAR = "{% if params.use_manual_date %}{{ params.manual_year }}{% else %}{{ logical_date.strftime('%Y') }}{% endif %}"
# GET_MONTH = "{% if params.use_manual_date %}{{ params.manual_month }}{% else %}{{ logical_date.strftime('%m') }}{% endif %}"
#
#
# # --- H√ÄM T·∫†O DAG (DAG FACTORY) ---
# def create_taxi_dag(taxi_type):
#     """
#     H√†m n√†y s·∫Ω sinh ra m·ªôt DAG object ri√™ng bi·ªát cho t·ª´ng lo·∫°i taxi
#     """
#     dag_id = f'nyc_taxi_{taxi_type}_etl'
#
#     with DAG(
#             dag_id=dag_id,
#             schedule='@monthly',
#             start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
#             end_date=pendulum.datetime(2023, 10, 31, tz="UTC"),
#             catchup=True,
#             max_active_runs=1,  # Gi·ªØ th·ª© t·ª± tu·∫ßn t·ª± cho t·ª´ng lo·∫°i xe
#             tags=['duckdb', 'minio', 'hybrid', taxi_type],
#             default_args={
#                 'retries': 2,
#                 'retry_delay': timedelta(minutes=1),
#                 'depends_on_past': True  # Th√°ng sau ƒë·ª£i th√°ng tr∆∞·ªõc (c·ªßa c√πng lo·∫°i xe)
#             },
#             # Params ri√™ng cho t·ª´ng DAG
#             params={
#                 "use_manual_date": Param(
#                     default=False,
#                     type="boolean",
#                     title="‚ö° Ch·∫ø ƒë·ªô ch·∫°y th·ªß c√¥ng?",
#                     description="T√≠ch ƒë·ªÉ nh·∫≠p nƒÉm/th√°ng b·∫±ng tay."
#                 ),
#                 "manual_year": Param(default="2024", type="string", title="NƒÉm (Manual)"),
#                 "manual_month": Param(default="01", type="string", title="Th√°ng (Manual)",
#                                       enum=[f"{i:02}" for i in range(1, 13)]),
#                 # Kh√¥ng c·∫ßn param ch·ªçn taxi_type n·ªØa v√¨ DAG n√†y ƒë√£ c·ªë ƒë·ªãnh lo·∫°i xe
#             }
#     ) as dag:
#         # 1. Task Ingest (Ch·∫°y song song tho·∫£i m√°i)
#         # Truy·ªÅn taxi_type c·ª©ng v√†o ƒë√¢y
#         s3_path = ingest_to_minio_bronze(
#             taxi_type=taxi_type,
#             year=GET_YEAR,
#             month=GET_MONTH
#         )
#         # 2. Task Merge (C·∫¶N POOL ƒê·ªÇ TR√ÅNH LOCK)
#         # S·ª≠ d·ª•ng .override() ƒë·ªÉ g√°n Pool
#         merge_to_silver_duckdb_native.override(
#             task_id=f'merge_{taxi_type}_to_duckdb',
#             pool='duckdb_write_pool'  # <--- CH√åA KH√ìA QUAN TR·ªåNG
#         )(
#             s3_path_bronze=s3_path,
#             taxi_type=taxi_type
#         )
#     return dag
#
#
# # --- KH·ªûI T·∫†O C√ÅC DAG ---
# # Airflow s·∫Ω t√¨m th·∫•y 2 bi·∫øn to√†n c·ª•c n√†y v√† ƒëƒÉng k√Ω th√†nh 2 DAGs tr√™n UI
# yellow_taxi_dag = create_taxi_dag('yellow')
# green_taxi_dag = create_taxi_dag('green')
# from airflow import DAG
# from airflow.models.param import Param
# from airflow.operators.bash import BashOperator
# from airflow.datasets import Dataset  # <--- Import m·ªõi quan tr·ªçng
# from datetime import timedelta
# import pendulum
#
# # Import tasks t·ª´ module c·ªßa b·∫°n
# from ELT.extract.extract import ingest_to_minio_bronze
# from ELT.load.load import merge_to_silver_duckdb_native
#
# # --- 1. ƒê·ªäNH NGHƒ®A DATASETS (T√çN HI·ªÜU) ---
# # ƒê√¢y l√† "ƒë·ªãa ch·ªâ" ƒë·ªÉ Airflow bi·∫øt ai xong vi·ªác
# DATASET_YELLOW = Dataset("duckdb://nyc_taxi_yellow")
# DATASET_GREEN = Dataset("duckdb://nyc_taxi_green")
#
# # --- C·∫§U H√åNH LOGIC NG√ÄY ---
# GET_YEAR = "{% if params.use_manual_date %}{{ params.manual_year }}{% else %}{{ logical_date.strftime('%Y') }}{% endif %}"
# GET_MONTH = "{% if params.use_manual_date %}{{ params.manual_month }}{% else %}{{ logical_date.strftime('%m') }}{% endif %}"
#
#
# # --- 2. H√ÄM T·∫†O DAG INGEST (PRODUCER) ---
# def create_ingest_dag(taxi_type):
#     dag_id = f'nyc_taxi_{taxi_type}_ingest'
#
#     # Ch·ªçn ƒë√∫ng Dataset d·ª±a tr√™n lo·∫°i xe
#     target_dataset = DATASET_YELLOW if taxi_type == 'yellow' else DATASET_GREEN
#
#     with DAG(
#             dag_id=dag_id,
#             schedule='@monthly',
#             start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
#             end_date=pendulum.datetime(2023, 10, 31, tz="UTC"),
#             catchup=True,
#             max_active_runs=1,
#             tags=['ingest', 'duckdb', taxi_type],
#             default_args={
#                 'retries': 2,
#                 'retry_delay': timedelta(minutes=1),
#                 'depends_on_past': True
#             },
#             params={
#                 "use_manual_date": Param(False, type="boolean", title="Ch·∫°y th·ªß c√¥ng?"),
#                 "manual_year": Param("2024", type="string", title="NƒÉm"),
#                 "manual_month": Param("01", type="string", title="Th√°ng", enum=[f"{i:02}" for i in range(1, 13)]),
#             }
#     ) as dag:
#         # B∆∞·ªõc 1: T·∫£i file v·ªÅ MinIO
#         s3_path = ingest_to_minio_bronze(
#             taxi_type=taxi_type,
#             year=GET_YEAR,
#             month=GET_MONTH
#         )
#
#         # B∆∞·ªõc 2: Load v√†o DuckDB Raw + B·∫ÆN T√çN HI·ªÜU (Outlets)
#         # L∆∞u √Ω: L√∫c n√†y h√†m merge c·ªßa b·∫°n n√™n ch·ªâ ƒë∆°n thu·∫ßn l√† Load Raw (nh∆∞ ƒë√£ b√†n)
#         # N·∫øu ch∆∞a s·ª≠a code load.py, c·ª© ƒë·ªÉ n√≥ ch·∫°y t·∫°m, dbt s·∫Ω ch·∫°y ƒë√® l√™n sau.
#         merge_to_silver_duckdb_native.override(
#             task_id=f'load_{taxi_type}_raw',
#             pool='duckdb_write_pool',  # V·∫´n c·∫ßn pool ƒë·ªÉ tr√°nh l·ªói lock khi ghi
#             outlets=[target_dataset]  # <--- B√°o hi·ªáu: "T√¥i ƒë√£ n·∫°p xong data n√†y!"
#         )(
#             s3_path_bronze=s3_path,
#             taxi_type=taxi_type
#         )
#
#     return dag
#
#
# # --- 3. KH·ªûI T·∫†O DAG INGEST ---
# yellow_ingest_dag = create_ingest_dag('yellow')
# green_ingest_dag = create_ingest_dag('green')
#
# # --- 4. T·∫†O DAG DBT TRANSFORM (CONSUMER) ---
# # DAG n√†y s·∫Ω t·ª± ch·∫°y khi C√ì T√çN HI·ªÜU t·ª´ dataset
# with DAG(
#         dag_id='nyc_taxi_dbt_transform',
#         # Schedule n√†y nghƒ©a l√†: Ch·ªù 1 trong 2, ho·∫∑c c·∫£ 2 (t√πy config dataset trigger)
#         # M·∫∑c ƒë·ªãnh Airflow: Khi Dataset ƒë∆∞·ª£c update, DAG n√†y s·∫Ω trigger.
#         schedule=[DATASET_YELLOW, DATASET_GREEN],
#         start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
#         catchup=False,  # dbt kh√¥ng c·∫ßn ch·∫°y b√π l·ªãch s·ª≠, n√≥ lu√¥n build tr√™n data hi·ªán t·∫°i
#         max_active_runs=1,  # Ch·ªâ cho ph√©p 1 ti·∫øn tr√¨nh dbt ch·∫°y t·∫°i 1 th·ªùi ƒëi·ªÉm
#         tags=['dbt', 'transform', 'gold']
# ) as dbt_dag:
#     # Task ch·∫°y dbt build
#     # L∆∞u √Ω: -t prod ƒë·ªÉ d√πng profile production k·∫øt n·ªëi ƒë√∫ng host
#     dbt_build = BashOperator(
#         task_id='dbt_build_all',
#         bash_command='cd /opt/airflow/dbt_project && dbt deps && dbt build -t prod --profiles-dir .'
#     )
#     # (T√πy ch·ªçn) Task xu·∫•t file View ra cho DBeaver xem (nh∆∞ ƒë√£ b√†n tr∆∞·ªõc ƒë√≥)
#     # publish_view_task = ... (Code Python task publish)
#     # dbt_build >> publish_view_task
#     # th√™m dbt docs generate
from airflow import DAG
from airflow.models.param import Param
from airflow.operators.bash import BashOperator
from airflow.decorators import task
from airflow.datasets import Dataset
from datetime import timedelta
import pendulum
import os
import duckdb
import shutil

# Import tasks t·ª´ module c·ªßa b·∫°n
from ELT.extract.extract import ingest_to_minio_bronze
from ELT.load.load import merge_to_silver_duckdb_native

# --- 1. ƒê·ªäNH NGHƒ®A DATASETS ---
DATASET_YELLOW = Dataset("duckdb://nyc_taxi_yellow")
DATASET_GREEN = Dataset("duckdb://nyc_taxi_green")

# --- C·∫§U H√åNH ---
GET_YEAR = "{% if params.use_manual_date %}{{ params.manual_year }}{% else %}{{ logical_date.strftime('%Y') }}{% endif %}"
GET_MONTH = "{% if params.use_manual_date %}{{ params.manual_month }}{% else %}{{ logical_date.strftime('%m') }}{% endif %}"


# ==========================================
# DAG 1 & 2: INGESTION (PRODUCER)
# ==========================================
def create_ingest_dag(taxi_type):
    dag_id = f'nyc_taxi_{taxi_type}_ingest'
    target_dataset = DATASET_YELLOW if taxi_type == 'yellow' else DATASET_GREEN

    with DAG(
            dag_id=dag_id,
            schedule='@monthly',
            start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
            end_date=pendulum.datetime(2023, 10, 31, tz="UTC"),
            catchup=True,
            max_active_runs=1,
            tags=['ingest', 'duckdb', taxi_type],
            default_args={'retries': 2, 'retry_delay': timedelta(minutes=1), 'depends_on_past': True},
            params={
                "use_manual_date": Param(False, type="boolean", title="Ch·∫°y th·ªß c√¥ng?"),
                "manual_year": Param("2024", type="string", title="NƒÉm"),
                "manual_month": Param("01", type="string", title="Th√°ng", enum=[f"{i:02}" for i in range(1, 13)]),
            }
    ) as dag:
        s3_path = ingest_to_minio_bronze(
            taxi_type=taxi_type,
            year=GET_YEAR,
            month=GET_MONTH
        )

        # Load Raw & B·∫Øn t√≠n hi·ªáu Dataset
        merge_to_silver_duckdb_native.override(
            task_id=f'load_{taxi_type}_raw',
            pool='duckdb_write_pool',
            outlets=[target_dataset]
        )(
            s3_path_bronze=s3_path,
            taxi_type=taxi_type
        )
    return dag


yellow_ingest_dag = create_ingest_dag('yellow')
green_ingest_dag = create_ingest_dag('green')


# ==========================================
# DAG 3: TRANSFORM & PUBLISH (CONSUMER)
# ==========================================

# ƒê·ªãnh nghƒ©a h√†m Publish View (Python Task)
@task(task_id="publish_view_db")
def publish_to_view_layer():
    # ƒê∆∞·ªùng d·∫´n n·ªôi b·ªô (DB g·ªëc - n∆°i dbt ch·∫°y)
    INTERNAL_DB = '/opt/airflow/duckdb_data/nyc_taxi.duckdb'

    # ƒê∆∞·ªùng d·∫´n xu·∫•t ra (Map v·ªõi host ./dbeaver_view th√¥ng qua docker volume)
    EXPORT_PATH = '/opt/airflow/export_view/nyc_taxi_view.duckdb'

    print(f"üîÑ B·∫Øt ƒë·∫ßu Export t·ª´ {INTERNAL_DB} sang {EXPORT_PATH}...")

    try:
        # L∆∞u √Ω: check point c·∫ßn quy·ªÅn ghi, n√™n read_only ph·∫£i l√† False
        with duckdb.connect(INTERNAL_DB, read_only=False) as con:
            con.sql("CHECKPOINT")
            print("‚úÖ ƒê√£ Checkpoint (Merge WAL) th√†nh c√¥ng.")
    except Exception as e:
        print(f"‚ö†Ô∏è C·∫£nh b√°o Checkpoint (C√≥ th·ªÉ b·ªè qua n·∫øu DB ƒëang b·∫≠n): {e}")

        # B∆Ø·ªöC 2: X√ìA FILE C≈®
    if os.path.exists(EXPORT_PATH):
        try:
            os.remove(EXPORT_PATH)
            print("üóëÔ∏è ƒê√£ x√≥a file view c≈©.")
        except OSError:
            print("‚ö†Ô∏è Kh√¥ng th·ªÉ x√≥a file c≈© (Streamlit ƒëang gi·ªØ?). S·∫Ω th·ª≠ ghi ƒë√®.")

        # B∆Ø·ªöC 3: COPY FILE (THAY TH·∫æ VACUUM INTO)
    try:
        # shutil.copy2 gi√∫p copy file gi·ªØ nguy√™n metadata
        shutil.copy2(INTERNAL_DB, EXPORT_PATH)
        print(f"‚úÖ ƒê√£ copy file th√†nh c√¥ng sang: {EXPORT_PATH}")
    except Exception as e:
        print(f"‚ùå L·ªói khi copy file: {e}")
        raise e


with DAG(
        dag_id='nyc_taxi_dbt_transform',
        # Ch·∫°y khi M·ªòT TRONG HAI dataset ƒë∆∞·ª£c c·∫≠p nh·∫≠t
        schedule=[DATASET_YELLOW, DATASET_GREEN],
        start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
        catchup=False,
        max_active_runs=1,
        tags=['dbt', 'transform', 'gold', 'docs']
) as dbt_dag:
    # 1. dbt Build (Ch·∫°y Model + Test)
    # L∆∞u √Ω ƒë∆∞·ªùng d·∫´n: cd /opt/airflow/dbt_project (Kh·ªõp v·ªõi docker-compose m·ªõi c·ªßa b·∫°n)
    dbt_build = BashOperator(
        task_id='dbt_build_all',
        bash_command='cd /opt/airflow/dbt_project && dbt deps && dbt build -t prod --profiles-dir .',
        pool='duckdb_write_pool'  # D√πng chung pool ƒë·ªÉ tr√°nh xung ƒë·ªôt v·ªõi Ingest
    )

    # 2. dbt Docs (T·∫°o t√†i li·ªáu)
    # L·ªánh n√†y s·∫Ω t·∫°o ra file index.html trong /opt/airflow/dbt_project/target/
    dbt_docs = BashOperator(
        task_id='dbt_generate_docs',
        bash_command='cd /opt/airflow/dbt_project && dbt docs generate -t prod --profiles-dir .',
        pool='duckdb_write_pool'
    )

    # 3. Publish View (Xu·∫•t file ra ngo√†i cho DBeaver/Streamlit)
    publish_task = publish_to_view_layer()

    # --- Lu·ªìng ch·∫°y ---
    dbt_build >> dbt_docs >> publish_task